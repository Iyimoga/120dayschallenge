{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Representing phrases – phrase2vec"
      ],
      "metadata": {
        "id": "fa6w19NkRO1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding words is useful, but usually, we deal with more complex units, such as phrases\n",
        "and sentences. Phrases are important because they specify more detail than just words.\n",
        "For example, the phrase delicious fried rice is very diﬀerent than just the word rice.\n",
        "In this recipe, we will train a word2vec model that uses phrases as well as words."
      ],
      "metadata": {
        "id": "P8QZmhkUDKI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTATION"
      ],
      "metadata": {
        "id": "mSfE8ybEDPAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKHQpUwDEOsQ",
        "outputId": "d084daba-6cea-4e9e-d207-8c1b9f9a89f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import Word2Vec\n",
        "import logging"
      ],
      "metadata": {
        "id": "PQMX24yBAcQP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP logging"
      ],
      "metadata": {
        "id": "ZCyBVIukFO21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level = logging.INFO)"
      ],
      "metadata": {
        "id": "cFO-XYv8D8Cs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CORPUS"
      ],
      "metadata": {
        "id": "FDnSTKpdGaIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    ['i', 'love', 'the', 'happy', 'hour', 'specials'],\n",
        "    ['san', 'francisco', 'is', 'a', 'beautiful', 'city'],\n",
        "    ['we', 'went', 'to', 'san', 'francisco', 'for', 'a', 'drink'],\n",
        "    ['the', 'bar', 'has', 'the', 'best', 'happy', 'hour'],\n",
        "    ['can', 'we', 'go', 'to', 'san', 'francisco', 'next', 'week'],\n",
        "    ['i', 'always', 'recommend', 'the', 'happy', 'hour', 'menu']\n",
        "]\n",
        "\n",
        "for sentence in corpus:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaQpcwubGYsF",
        "outputId": "8dd9f1c4-e5ea-43ca-eb91-e15b653d95d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'love', 'the', 'happy', 'hour', 'specials']\n",
            "['san', 'francisco', 'is', 'a', 'beautiful', 'city']\n",
            "['we', 'went', 'to', 'san', 'francisco', 'for', 'a', 'drink']\n",
            "['the', 'bar', 'has', 'the', 'best', 'happy', 'hour']\n",
            "['can', 'we', 'go', 'to', 'san', 'francisco', 'next', 'week']\n",
            "['i', 'always', 'recommend', 'the', 'happy', 'hour', 'menu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "phrase2vec"
      ],
      "metadata": {
        "id": "nzdcvoooHOuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# phrase model training\n",
        "bigram_model = Phrases(corpus, min_count=2, threshold=2)"
      ],
      "metadata": {
        "id": "luj5A4p6Gk18"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# phraser object\n",
        "bigram_phraser = Phraser(bigram_model)"
      ],
      "metadata": {
        "id": "sv-1DpZFHtMk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply phraser to corpus\n",
        "phrased_corpus = [bigram_phraser[sentence] for sentence in corpus]\n",
        "\n",
        "for sentence in phrased_corpus:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11HjHCx6IBC7",
        "outputId": "af3c3e01-6a65-4b5a-ef92-b8df90a2440e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'love', 'the', 'happy_hour', 'specials']\n",
            "['san_francisco', 'is', 'a', 'beautiful', 'city']\n",
            "['we', 'went', 'to', 'san_francisco', 'for', 'a', 'drink']\n",
            "['the', 'bar', 'has', 'the', 'best', 'happy_hour']\n",
            "['can', 'we', 'go', 'to', 'san_francisco', 'next', 'week']\n",
            "['i', 'always', 'recommend', 'the', 'happy_hour', 'menu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN word2vec on the new corpus"
      ],
      "metadata": {
        "id": "I8-jhMK8I4_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(\n",
        "    phrased_corpus,\n",
        "    vector_size = 20,\n",
        "    window = 3,\n",
        "    min_count = 1,\n",
        "    sg = 1\n",
        ")\n",
        "\n",
        "print(\"\\nSuccessful Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTOHS_AHIkHL",
        "outputId": "0e1708ba-3fb6-4e42-da6b-ce16cf398711"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successful Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST PHRASE EMBEDDINGS"
      ],
      "metadata": {
        "id": "QnBH1tt4MC7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = \"happy_hour\"\n",
        "if phrase in model.wv:\n",
        "  print(f\"\\nVector for '{phrase}' exists in the model vocabulary\")\n",
        "\n",
        "  similar_tokens = model.wv.most_similar(phrase, topn=3)\n",
        "  for token, score in similar_tokens:\n",
        "    print(f\"'{token}: ' {score:.3f}\")\n",
        "\n",
        "  else:\n",
        "    print(f\"{phrase} was not frequent enough to be included in the model.\")\n",
        "\n",
        "  phrase_2 = \"san_francisco\"\n",
        "  if phrase_2 in model.wv:\n",
        "    print(f\"tokens most similar to '{phrase_2}':\")\n",
        "    similar_token_2 = model.wv.most_similar(phrase_2, topn = 3)\n",
        "    for token, score in similar_token_2:\n",
        "      print(f\"{token}: {score: .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBFtIjeFJkFK",
        "outputId": "a13c0426-c483-417e-c360-a4f36a893f1c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vector for 'happy_hour' exists in the model vocabulary\n",
            "'has: ' 0.387\n",
            "'city: ' 0.257\n",
            "'to: ' 0.230\n",
            "happy_hour was not frequent enough to be included in the model.\n",
            "tokens most similar to 'san_francisco':\n",
            "went:  0.437\n",
            "week:  0.254\n",
            "has:  0.159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MXBrUGkfOa9D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}