{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a basic image classifer**"
      ],
      "metadata": {
        "id": "16QskFdvptv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementing an image classifer on Fashion-MNIST, a\n",
        "popular alternative to mnist"
      ],
      "metadata": {
        "id": "-qzr7AD_qCJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkFWVnVbpsbL",
        "outputId": "c0d8e9fd-f7d6-4716-cea3-2636495feaf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/tensorflow/docs\n",
            "  Cloning https://github.com/tensorflow/docs to /tmp/pip-req-build-25zhwzv9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs /tmp/pip-req-build-25zhwzv9\n",
            "  Resolved https://github.com/tensorflow/docs to commit e21d085d5ed82504ffcec11aa82ebc78f1f2302e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astor (from tensorflow-docs==2025.3.6.10029)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from tensorflow-docs==2025.3.6.10029) (1.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from tensorflow-docs==2025.3.6.10029) (3.1.6)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from tensorflow-docs==2025.3.6.10029) (5.10.4)\n",
            "Requirement already satisfied: protobuf>=3.12 in /usr/local/lib/python3.12/dist-packages (from tensorflow-docs==2025.3.6.10029) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from tensorflow-docs==2025.3.6.10029) (6.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->tensorflow-docs==2025.3.6.10029) (3.0.3)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat->tensorflow-docs==2025.3.6.10029) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs==2025.3.6.10029) (4.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->tensorflow-docs==2025.3.6.10029) (4.15.0)\n",
            "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Building wheels for collected packages: tensorflow-docs\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2025.3.6.10029-py3-none-any.whl size=186351 sha256=cbcd0a9b35310a7ce32f1db97fadf4bb4da6617bfcc0bc2aade86fe2b524cb50\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5p9_xz0t/wheels/3e/88/34/48d2789bc9d37b33ddce06bccc454fae0285e5396d0a5be9d9\n",
            "Successfully built tensorflow-docs\n",
            "Installing collected packages: astor, tensorflow-docs\n",
            "Successfully installed astor-0.8.1 tensorflow-docs-2025.3.6.10029\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots # modules that provide utilities and functions to help document TensorFlow models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer #  A utility to convert categorical labels into binary format (one-hot encoding\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import fashion_mnist as fm\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D # Neural Network layer\n",
        "from tensorflow.keras.layers import Dense # Neural Network layer\n",
        "from tensorflow.keras.layers import Dropout # Neural Network layer\n",
        "from tensorflow.keras.layers import ELU # Exponential Linear Unit (ELU) activation function to the input\n",
        "from tensorflow.keras.layers import Flatten # Neural Network layer\n",
        "from tensorflow.keras.layers import Input # Neural Network layer\n",
        "from tensorflow.keras.layers import MaxPooling2D # Neural Network layer\n",
        "from tensorflow.keras.layers import Softmax # Activation functio\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "JieLXW7lrxTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defne a function that will load and prepare the dataset. It will normalize the data,\n",
        "one-hot encode the labels, take a portion of the training set for validation, and wrap\n",
        "the three data subsets into three separate tf.data.Dataset instances to increase\n",
        "performance using from_tensor_slices():"
      ],
      "metadata": {
        "id": "9KR_Kpz3sPMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    (X_train, y_train), (X_test, y_test) = fm.load_data()\n",
        "    X_train = X_train.astype('float32') / 255.0\n",
        "    X_test = X_test.astype('float32') / 255.0\n",
        "    # Reshape grayscale to include channel dimension.\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "    X_test = np.expand_dims(X_test, axis=3)\n",
        "    label_binarizer = LabelBinarizer()\n",
        "    y_train = label_binarizer.fit_transform(y_train)\n",
        "    y_test = label_binarizer.fit_transform(y_test)\n",
        "    (X_train, X_val,y_train, y_val) = train_test_split(X_train, y_train,train_size=0.8)\n",
        "    train_ds = (tf.data.Dataset.from_tensor_slices((X_train,y_train)))\n",
        "    val_ds = (tf.data.Dataset.from_tensor_slices((X_val, y_val)))\n",
        "    test_ds = (tf.data.Dataset.from_tensor_slices((X_test, y_test)))"
      ],
      "metadata": {
        "id": "f2ow0V-ssIDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement a function that will build a network similar to LeNet with the addition\n",
        "of BatchNormalization, which we'll use to make the network faster and most\n",
        "stable, and Dropout layers, which will help us combat overftting, a situation where\n",
        "the network loses generalization power due to high variance:"
      ],
      "metadata": {
        "id": "nNEpB5AcuSGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_network():\n",
        "    input_layer = Input(shape=(28, 28, 1))\n",
        "    x = Conv2D(filters=20,\n",
        "    kernel_size=(5, 5),\n",
        "    padding='same',\n",
        "    strides=(1, 1))(input_layer)\n",
        "    x = ELU()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2),\n",
        "    strides=(2, 2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Conv2D(filters=50,\n",
        "    kernel_size=(5, 5),\n",
        "    padding='same',\n",
        "    strides=(1, 1))(x)\n",
        "    x = ELU()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2),\n",
        "    strides=(2, 2))(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(units=500)(x)\n",
        "    x = ELU()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(10)(x)\n",
        "    output = Softmax()(x)\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "a78GwLIeselr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2zYQ8Mhu6EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defne a function that takes a model's training history, along with a metric of\n",
        "interest, to create a plot corresponding to the training and validation of the curves\n",
        "of such a metric:"
      ],
      "metadata": {
        "id": "hWR7RhLTvV7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_history(model_history, metric, ylim=None):\n",
        "    plt.style.use('seaborn-darkgrid')\n",
        "    plotter = tfdocs.plots.HistoryPlotter()\n",
        "    plotter.plot({'Model': model_history}, metric=metric)\n",
        "    plt.title(f'{metric.upper()}')\n",
        "    if ylim is None:\n",
        "      plt.ylim([0, 1])\n",
        "    else:\n",
        "      plt.ylim(ylim)\n",
        "    plt.savefig(f'{metric}.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "UteFvoMYvX_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-xJcphjcxRLK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}