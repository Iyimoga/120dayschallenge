{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac5e563-9713-4b75-bcb4-f948f20fe536",
   "metadata": {},
   "source": [
    "# IMPLEMENTING DEEPDREAM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2c929ac-e449-44c5-8f7c-c6fe6c8687f9",
   "metadata": {},
   "source": [
    "DeepDream is the result of an experiment that aimed to visualize the internal patterns\n",
    "that are learned by a neural network. In order to achieve this goal, we can pass an image\n",
    "through the network, compute its gradient with respect to the activations of a specifc\n",
    "layer, and then modify the image to increase the magnitude of such activations to, in turn,\n",
    "magnify the patterns. Te result? Psychedelic, surreal photos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077d1ed-db71-455e-b1f0-02d69773a5c0",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f52b558e-4abf-40f5-942b-f8082a1412d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.inception_v3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573825af-59b2-4e40-b404-1b2736bebf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDreamer(object):\n",
    "    def __init__(self,\n",
    "                octave_scale = 1.30, # Determines how much the image size changes between \"octaves\" (levels of detail/resolution).\n",
    "                octave_power_factors = None, # Controls the range of octaves, default is [-2, -1, 0, 1, 2]\n",
    "                layers = None):\n",
    "\n",
    "        '''\n",
    "The constructor parameters specify the scale by which we'll increase the size of\n",
    "an image (octave_scale), as well as the factor that will applied to the scale\n",
    "(octave_power_factors). layers contains the target layers that will be used\n",
    "to generate the dreams. Next, let's store the parameters as object members:\n",
    "        '''\n",
    "        self.octave_scale = octave_scale\n",
    "        if octave_power_factors is None:\n",
    "            self.octave_power_factors = [*range(-2, 3)]\n",
    "        else:\n",
    "            self.octave_power_factors = octave_power_factors\n",
    "        if layers is None:\n",
    "            self.layers = [\"mixed3\", \"mixed5\"]\n",
    "        else:\n",
    "            self.layers = layers\n",
    "        '''\n",
    "If some of the inputs are None, we use defaults. If not, we use the inputs.\n",
    "Finally, create the dreamer model by extracting our layers from a pre-trained\n",
    "InceptionV3 network:\n",
    "        '''\n",
    "        self.base_model = InceptionV3(weights = \"imagenet\",   #  Loads the pre-trained InceptionV3 convolutional neural network, without its classification layer.\n",
    "                                     include_top = False)\n",
    "        outputs = [self.base_model.get_layer(name).output\n",
    "                  for name in self.layers]\n",
    "        self.dreamer_model = Model(self.base_model.input,\n",
    "                                  outputs)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cedbbf8-c03c-4202-812a-5c3258a06a5a",
   "metadata": {},
   "source": [
    "DEFINE A PRIVATE METHOD THAT WILL COMPUTE THE LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57f7fc4-eb2a-4f96-b0ae-30a6908a26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_loss(self, image):\n",
    "    image_batch = tf.expand_dims(image, axis = 0) # Adds a batch dimension to the image  into a batch of one image (shape: 1 × height × width × channels).\n",
    "    activations = self.dreamer_model(image_batch) # urpose: Passes the image through the DeepDream model to get the activations (outputs)\n",
    "\n",
    "    if len(activations) == 1: # Ensures that activations is always a list, even if there's only one layer.\n",
    "        activations = [activations]\n",
    "\n",
    "    losses = []\n",
    "    for activation in activations:\n",
    "        loss = tf.math.reduce_mean(activation)\n",
    "        losses.append(loss)\n",
    "\n",
    "    total_loss = tf.reduce_sum(losses)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59779fd-5828-4e16-afc6-7b8b641c7100",
   "metadata": {},
   "source": [
    "DEFINE A PRIVATE METHOD THAT WILL PERFORM GRADIENT ASCENT(REMEMBER, WE WANT TO MAGNIFY THE PATTERNS OF THE IMAGE). TO INCREASE PERFORMANCE, WE CAN WRAP THIS FUNCTION IN TF.FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b40d9f2-da84-4950-915e-95bf6dc062c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function # This tells TensorFlow to compile the function into a fast, optimized graph for performance.\n",
    "def _gradient_ascent(self, image, steps, step_size): #  Runs gradient ascent for a set number of steps to \"amplify\" patterns in the image.\n",
    "    loss = tf.constant(0.0) # Starts with a loss value of zero. This will be updated each step.\n",
    "\n",
    "    for _ in range(steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(image)\n",
    "            loss = self._calculate_loss(image)\n",
    "\n",
    "        gradeients = tape.gradient(loss, image)\n",
    "        gradients /= tf.reduce_std(gradients) + le-8\n",
    "\n",
    "        image = image + gradients * step_size\n",
    "        image = tf.clip_by_vakue(image, -1, 1)\n",
    "    return loss, image\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee65995-bd40-4ce8-89e0-fc3394878c5c",
   "metadata": {},
   "source": [
    "DEFINE A PRIVATE METHOD THAT WILL CONVERT THE IMAGE TENSOR GENERATED BY THE DREAMER BACK INTO A NUMPY ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6dbe283-9d51-4143-a7bf-620b2b434f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deprocess(self, image):\n",
    "    image = 255 * (image + 1.0) / 2.0 # Neural networks often process images with pixel values normalized to the range [−1,1][−1,1]\n",
    "    image = tf.cast(image, tf.uint8) # Converts the image data type to uint8, which is the standard for image files\n",
    "    image = np.array(image) # Converts the TensorFlow tensor to a NumPy array, making it compatible with most image processing libraries and functions.\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4a117-9009-4fa4-af94-f2abbfee94a7",
   "metadata": {},
   "source": [
    "DEFINE A PRIVATE METHOD THAT WILL GENERATE A DREAMY IMAGE BY PERFORMING GRADIENT_ASCENT() FOR A SPECOFIC NUMBER OF STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "685e74af-4132-48f0-939e-903deb6a0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dream(self, image, steps, step_size):\n",
    "    # Converts the input image to the format expected by the neural network (usually scaling pixel values to [−1,1][−1,1] \n",
    "    # and converting to a TensorFlow tensor).\n",
    "    image = preprocess_input(image)\n",
    "    image = tf.convert_to_tensor(image)\n",
    "\n",
    "    #  Ensures step_size is a TensorFlow constant, which is required for TensorFlow operations inside the loop.\n",
    "    step_size = tf.convert_to_tensor(step_size)\n",
    "    step_size = tf.constant(step_size)\n",
    "\n",
    "    # Purpose: Tracks how many steps are left and the current step number.\n",
    "    steps_remaining  = steps\n",
    "    current_step = 0\n",
    "\n",
    "    \n",
    "\n",
    "    #Runs the gradient ascent process in chunks of up to 100 steps at a time (this helps with memory and performance).\n",
    "\n",
    "    #Calls self._gradient_ascent to update the image, maximizing the activations in the chosen layers.\n",
    "\n",
    "    #Updates counters after each chunk.\n",
    "\n",
    "    while steps_remaining > 0:\n",
    "        if steps_remaining > 100:\n",
    "            run_steps = tf.constant(100)\n",
    "        else:\n",
    "            run_steps = tf.constant(steps_remaining)\n",
    "\n",
    "        steps_remaining -= run_steps\n",
    "        current_step += run_steps\n",
    "\n",
    "        loss, image = self._gradient_ascent(image, run_steps,\n",
    "                                           step_size)\n",
    "\n",
    "    # Converts the processed image tensor back to a standard image format\n",
    "    result = self._deprocess(image)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c6ae4-8cdd-4f42-b404-2fc1a289074a",
   "metadata": {},
   "source": [
    "DEFINE A PUBLIC METHOD THAT WILL GENERATE DREAMY IMAGES. THE MAIN DIFFERENCE BETWEEN THIS AND _DREAM() (DEFINED IN STEP 6 AND USED INTERNALLY HERE) IS THAT WE WILL USE DIFFERENT IMAGE SIZE (CALLED OCTAVES), AS DETERMINED BY THE ORIGINAL IMAGE SHAPE MULTIPLIED BY A FACTOR, WHICH IS THE PRODUCT OF POWERING SELF.OCTAVE_SCALE TO EACH POWER IN SELF.OCTAVE_POWER_FACTORS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "436ade62-720f-45a7-ac04-c7418d6055c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dream(self, image, steps = 100, step_size = 0.01):\n",
    "    image = tf.constant(np.array(image)) # Converts the input image (possibly a PIL or NumPy image) into a TensorFlow tensor\n",
    "    base_shape = tf.shape(image) [:-1] # Gets the height and width of the image (ignoring the color channels).\n",
    "    base_shape = tf.cast(base_shape, tf.float32) # Casts the shape to float32 for scaling calculations.\n",
    "    for factor in self.octave_power_factors:\n",
    "        new_shape = tf.cast(base_shape*(self.octave_scale ** factor),\n",
    "                           tf.int32)\n",
    "        image = tf.image.resize(image,\n",
    "                               new_shape).numpy()\n",
    "        image = self._dream(image, steps = steps,\n",
    "                           step_size = step_size)\n",
    "\n",
    "        image = tf.image.convert_image_dtype(image / 255.0,\n",
    "                                            dtype = tf.uint8)\n",
    "        image = np.array(image)\n",
    "\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "645c329c-531f-4233-9d44-473a4c21431b",
   "metadata": {},
   "source": [
    "The DeepDreamer() class can be reused to produce dream-like versions of any image we supply to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b650a92-5f99-4e9c-8c53-c8bfa19e8bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
