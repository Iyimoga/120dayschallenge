{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PERFORMING IMAGE CLASSIFICATION**"
      ],
      "metadata": {
        "id": "nhwtFCCginL8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ommN4Ova1U0E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function to load the images and labels from a list of file paths"
      ],
      "metadata": {
        "id": "UD22DrwEjzN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_labels(image_paths):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for image_path in image_paths:\n",
        "    image = load_img(image_path, target_size = (32, 32),\n",
        "                     color_mode = \"grayscale\")\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    label = image_path.split(os.path.sep) [-2]\n",
        "    label = \"positive\" in label\n",
        "    label = float(label)\n",
        "\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "  return np.array(images), np.array(labels)\n",
        "\n",
        "  \"\"\"\n",
        "Notice that we are loading the images in grayscale, and we're encoding the labels by\n",
        "checking whether the word positive is in the file path of the image\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "XgAwbDqaj95k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to build the neural network.\n",
        "This model's structure is based on LeNet"
      ],
      "metadata": {
        "id": "Q9yCvwxHlmg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_network():\n",
        "  input_layer = Input(shape = (32, 32, 1))\n",
        "  x = Conv2D(filters = 20,\n",
        "             kernel_size = (5, 5),\n",
        "             padding = \"same\",\n",
        "             strides = (1, 1)) (input_layer)\n",
        "  x = ELU()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size = (2, 2),\n",
        "                   strides = (2, 2)) (x)\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  x = Conv2D(filters = 50,\n",
        "             kernel_size = (5, 5),\n",
        "             padding = \"same\",\n",
        "             strides = (1, 1))(x)\n",
        "\n",
        "  x = ELU()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D(pool_size = (2, 2),\n",
        "                   strides = (2, 2))(x)\n",
        "\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(units = 500)(x)\n",
        "  x = ELU()(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "\n",
        "  output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "  model = Model(inputs = input_layer, outputs= output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "yzBP0vGNlOpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this is a binary classification problem, a single sigmoid-activated neuron is enough in the output layer"
      ],
      "metadata": {
        "id": "LnX1lK9Kop9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOAD THE IMAGE PATHS INTO THE LIST"
      ],
      "metadata": {
        "id": "PM8wVt8so7BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files_pattern = (pathlib.Path.home() / '.keras' /\n",
        "                'datasets' /\n",
        "                'SMILEsmileD-master' / 'SMILEs' / '*'\n",
        "                / '*' /\n",
        "                '*.jpg')\n",
        "files_pattern = str(files_pattern)\n",
        "dataset_paths = [*glob.glob(files_pattern)]"
      ],
      "metadata": {
        "id": "Ol8szmCwolZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# use the load_images_and_labels() function defined previously to load the dataset into memory"
      ],
      "metadata": {
        "id": "AG-HfkRxqFdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = load_images_and_labels(dataset_paths)\n"
      ],
      "metadata": {
        "id": "TnufiQU3p81B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalize the images and compute the number of positive, and the total examples in the dataset"
      ],
      "metadata": {
        "id": "6Yn0NVP2qt8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the images and compute the number of positive, and the total examples in the dataset\n",
        "x = x.astype(\"float32\") / 255.0\n",
        "\n",
        "total = len(y)\n",
        "total_positive = np.sum(y)\n",
        "total_negative = total - total_positive"
      ],
      "metadata": {
        "id": "dRSzfeBiqs3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create train, test, and validation subsets of the data"
      ],
      "metadata": {
        "id": "LFV9D-N5rmCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train, test, and validation subsets of the data\n",
        "(x_train, x_test, y_train, y_test) = train_test_split(x, y,\n",
        "                                                     test_size=0.15,\n",
        "                                                     stratify = y,\n",
        "                                                     random_state = 999)\n",
        "\n",
        "# Second split for validation set\n",
        "(x_train, x_val, y_train, y_val) = train_test_split(x_train, y_train,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify = y_train,\n",
        "                                                    random_state = 999)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "eowFczbVrd7R",
        "outputId": "59e8d68e-d10e-4324-ed5a-089655195033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2592412361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create train, test, and validation subsets of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m (x_train, x_test, y_train, y_test) = train_test_split(x, y,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                      \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                      \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                      random_state = 999)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "8d6ab73a",
        "outputId": "868fd003-e153-446e-9631-8e4ed90eb917"
      },
      "source": [
        "# Build the model\n",
        "model = build_network()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1935468346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     epochs=10, batch_size=32)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UY8FavYoswDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}