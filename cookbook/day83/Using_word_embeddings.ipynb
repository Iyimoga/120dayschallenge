{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naf-PLName0Q"
      },
      "source": [
        "# Using word embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntRWmJt8mkqK"
      },
      "source": [
        "In this recipe we switch gears and learn how to represent words using word embeddings,\n",
        "which are powerful because they are a result of training a neural network that predicts\n",
        "a word from all other words in the sentence. The resulting vector embeddings are\n",
        "similar for words that occur in similar contexts. We will use the embeddings to show\n",
        "these similarities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpxz3CQpnUD3"
      },
      "source": [
        "# How to do itâ€¦\n",
        "We will load the model, demonstrate some features of the gensim package, and then\n",
        "compute a sentence vector using the word embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jlpubcRnce5"
      },
      "source": [
        "IMPORTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLdHx8J1n3ym",
        "outputId": "261f3c1e-2a7c-4251-8286-ca1b0d6d661e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bZY0dF0TljOw"
      },
      "outputs": [],
      "source": [
        "from gensim.models import keyedvectors\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSkZm7B8ChGZ"
      },
      "source": [
        "ASSIGN THE MODEL PATH TO A VARIABLE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMsqFssgYyvZ",
        "outputId": "891fb914-8b8b-4ed2-e7ad-c6108629e5dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iNcXVWdsnn63"
      },
      "outputs": [],
      "source": [
        "word2vec_model_path = r\"/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "658XsfPeCurJ"
      },
      "source": [
        "LOAD THE PRETRAINED MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VhSHo7Bst1DZ"
      },
      "outputs": [],
      "source": [
        "model = keyedvectors.load_word2vec_format(word2vec_model_path, binary = True) # binary = True, this takes care of UnicodeDecodeError"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the pretrained model, we can now load individual word vectors:"
      ],
      "metadata": {
        "id": "-Ixj7mRQhnyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sFgzqA94DcyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46bf6432-0c74-4f75-85ac-bbf97ae8d37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.05419922  0.01708984 -0.00527954  0.33203125 -0.25       -0.01397705\n",
            " -0.15039062 -0.265625    0.01647949  0.3828125  -0.03295898 -0.09716797\n",
            " -0.16308594 -0.04443359  0.00946045  0.18457031  0.03637695  0.16601562\n",
            "  0.36328125 -0.25585938  0.375       0.171875    0.21386719 -0.19921875\n",
            "  0.13085938 -0.07275391 -0.02819824  0.11621094  0.15332031  0.09082031\n",
            "  0.06787109 -0.0300293  -0.16894531 -0.20800781 -0.03710938 -0.22753906\n",
            "  0.26367188  0.012146    0.18359375  0.31054688 -0.10791016 -0.19140625\n",
            "  0.21582031  0.13183594 -0.03515625  0.18554688 -0.30859375  0.04785156\n",
            " -0.10986328  0.14355469 -0.43554688 -0.0378418   0.10839844  0.140625\n",
            " -0.10595703  0.26171875 -0.17089844  0.39453125  0.12597656 -0.27734375\n",
            " -0.28125     0.14746094 -0.20996094  0.02355957  0.18457031  0.00445557\n",
            " -0.27929688 -0.03637695 -0.29296875  0.19628906  0.20703125  0.2890625\n",
            " -0.20507812  0.06787109 -0.43164062 -0.10986328 -0.2578125  -0.02331543\n",
            "  0.11328125  0.23144531 -0.04418945  0.10839844 -0.2890625  -0.09521484\n",
            " -0.10351562 -0.0324707   0.07763672 -0.13378906  0.22949219  0.06298828\n",
            "  0.08349609  0.02929688 -0.11474609  0.00534058 -0.12988281  0.02514648\n",
            "  0.08789062  0.24511719 -0.11474609 -0.296875   -0.59375    -0.29492188\n",
            " -0.13378906  0.27734375 -0.04174805  0.11621094  0.28320312  0.00241089\n",
            "  0.13867188 -0.00683594 -0.30078125  0.16210938  0.01171875 -0.13867188\n",
            "  0.48828125  0.02880859  0.02416992  0.04736328  0.05859375 -0.23828125\n",
            "  0.02758789  0.05981445 -0.03857422  0.06933594  0.14941406 -0.10888672\n",
            " -0.07324219  0.08789062  0.27148438  0.06591797 -0.37890625 -0.26171875\n",
            " -0.13183594  0.09570312 -0.3125      0.10205078  0.03063965  0.23632812\n",
            "  0.00582886  0.27734375  0.20507812 -0.17871094 -0.31445312 -0.01586914\n",
            "  0.13964844  0.13574219  0.0390625  -0.29296875  0.234375   -0.33984375\n",
            " -0.11816406  0.10644531 -0.18457031 -0.02099609  0.02563477  0.25390625\n",
            "  0.07275391  0.13574219 -0.00138092 -0.2578125  -0.2890625   0.10107422\n",
            "  0.19238281 -0.04882812  0.27929688 -0.3359375  -0.07373047  0.01879883\n",
            " -0.10986328 -0.04614258  0.15722656  0.06689453 -0.03417969  0.16308594\n",
            "  0.08642578  0.44726562  0.02026367 -0.01977539  0.07958984  0.17773438\n",
            " -0.04370117 -0.00952148  0.16503906  0.17285156  0.23144531 -0.04272461\n",
            "  0.02355957  0.18359375 -0.41601562 -0.01745605  0.16796875  0.04736328\n",
            "  0.14257812  0.08496094  0.33984375  0.1484375  -0.34375    -0.14160156\n",
            " -0.06835938 -0.14648438 -0.02844238  0.07421875 -0.07666016  0.12695312\n",
            "  0.05859375 -0.07568359 -0.03344727  0.23632812 -0.16308594  0.16503906\n",
            "  0.1484375  -0.2421875  -0.3515625  -0.30664062  0.00491333  0.17675781\n",
            "  0.46289062  0.14257812 -0.25       -0.25976562  0.04370117  0.34960938\n",
            "  0.05957031  0.07617188 -0.02868652 -0.09667969 -0.01281738  0.05859375\n",
            " -0.22949219 -0.1953125  -0.12207031  0.20117188 -0.42382812  0.06005859\n",
            "  0.50390625  0.20898438  0.11230469 -0.06054688  0.33203125  0.07421875\n",
            " -0.05786133  0.11083984 -0.06494141  0.05639648  0.01757812  0.08398438\n",
            "  0.13769531  0.2578125   0.16796875 -0.16894531  0.01794434  0.16015625\n",
            "  0.26171875  0.31640625 -0.24804688  0.05371094 -0.0859375   0.17089844\n",
            " -0.39453125 -0.00156403 -0.07324219 -0.04614258 -0.16210938 -0.15722656\n",
            "  0.21289062 -0.15820312  0.04394531  0.28515625  0.01196289 -0.26953125\n",
            " -0.04370117  0.37109375  0.04663086 -0.19726562  0.3046875  -0.36523438\n",
            " -0.23632812  0.08056641 -0.04248047 -0.14648438 -0.06225586 -0.0534668\n",
            " -0.05664062  0.18945312  0.37109375 -0.22070312  0.04638672  0.02612305\n",
            " -0.11474609  0.265625   -0.02453613  0.11083984 -0.02514648 -0.12060547\n",
            "  0.05297852  0.07128906  0.00063705 -0.36523438 -0.13769531 -0.12890625]\n"
          ]
        }
      ],
      "source": [
        "print(model[\"hello\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get words that are most similar to a given word. For example, let's print\n",
        "out the words most similar to hello (lowercase, since all the words are lowercased\n",
        "in the training process):"
      ],
      "metadata": {
        "id": "DuFviSU8qjKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar([\"hello\"], topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52jPwXHGpwUO",
        "outputId": "08f7fb2d-9553-4f1f-be0e-620768974167"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hi', 0.6548984050750732), ('goodbye', 0.6399056315422058), ('howdy', 0.6310956478118896), ('goodnight', 0.5920578241348267), ('greeting', 0.5855877995491028)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now also compute a sentence vector by averaging all the word vectors in the\n",
        "sentence. We will use the sentence It was not that he felt any emotion akin to love for\n",
        "Irene Adler:"
      ],
      "metadata": {
        "id": "dya-UsgDrq8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"It was not that he felt any emotion akin to love for Irene Adler.\""
      ],
      "metadata": {
        "id": "c73YaGRWrRAF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a function that will take a sentences and a model and will return a list of the sentence word vectors:"
      ],
      "metadata": {
        "id": "9ZgE4Ts4r42L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_vectors(sentence, model):\n",
        "  word_vectors = []\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      word_vector = model.get_vector(word.lower())\n",
        "      word_vectors.append(word_vector)\n",
        "    except KeyError:\n",
        "      continue\n",
        "  return word_vectors"
      ],
      "metadata": {
        "id": "5g0Qn-9Lr3hu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's defne a function that will take the word vector list and compute the\n",
        "sentence vector:"
      ],
      "metadata": {
        "id": "t5zA3nrTs4Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_vector(word_vectors):\n",
        "  matrix = np.array(word_vectors)\n",
        "  centroid = np.mean(matrix[:, :], axis = 0)\n",
        "  return centroid"
      ],
      "metadata": {
        "id": "l-FfspoRs1Bm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now compute the sentence vector:"
      ],
      "metadata": {
        "id": "1WQmMWFLtT9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = get_word_vectors(sentence, model)\n",
        "sentence_vector = get_sentence_vector(word_vectors)\n",
        "print(sentence_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O7uSRECtQPN",
        "outputId": "3edd88b1-fc91-4a9e-87d3-ecb93bf4300b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.1625751   0.117904   -0.03327743  0.13714865 -0.0290534   0.04307888\n",
            " -0.07734017 -0.02747113 -0.0376985   0.03732565 -0.04847514 -0.07030454\n",
            " -0.23939314  0.00413978 -0.11796238  0.10221531  0.11549311  0.17339823\n",
            " -0.01006516  0.01300944 -0.2710863  -0.04825393  0.14016724  0.04992394\n",
            " -0.10000245  0.04447595 -0.2545962   0.06052366 -0.0249793  -0.02394436\n",
            " -0.00060902  0.03851567 -0.05589493 -0.10330465 -0.12221361  0.09696181\n",
            " -0.21117567  0.09080704 -0.04517754  0.07360575 -0.05247696 -0.06609842\n",
            "  0.06061587  0.08914715  0.04468835 -0.04243366 -0.06161698 -0.1939538\n",
            " -0.1545702   0.09573762 -0.20171323  0.24152938 -0.04674497  0.25169572\n",
            "  0.05233366  0.13106106 -0.16313371 -0.08871593 -0.0040522  -0.16744332\n",
            " -0.15011995 -0.08387823 -0.17923239 -0.04825065 -0.03933384 -0.17564325\n",
            " -0.11914261  0.12546705 -0.07503078  0.06912629  0.04439644 -0.05143406\n",
            "  0.05790644  0.0139797  -0.05246701 -0.01477847  0.14195849  0.02867591\n",
            " -0.00335229 -0.09226393 -0.13522206 -0.02071812 -0.05869525 -0.01276431\n",
            "  0.13344409  0.08639792  0.0054507   0.19712497  0.00597813  0.04386039\n",
            " -0.0032269   0.04255477 -0.03392759 -0.16415273  0.03406293  0.10536923\n",
            " -0.09740149  0.12093851  0.2836861  -0.0237931  -0.10344132 -0.009688\n",
            " -0.08537491 -0.01060685 -0.06330075  0.14890455 -0.09241121  0.03505408\n",
            " -0.00097922  0.0152495  -0.15107794 -0.18330716 -0.01302868 -0.02344413\n",
            "  0.06639878  0.1630302   0.08454058 -0.02822677 -0.05497343 -0.03960601\n",
            "  0.09736832  0.07984991 -0.0061619   0.01936937  0.11513353 -0.18249777\n",
            " -0.14144234 -0.06209664  0.0440435   0.1095868  -0.07652084 -0.03040347\n",
            " -0.07486293 -0.05231111 -0.17671585  0.07859222 -0.04752914  0.03138534\n",
            "  0.2639903   0.13312033  0.18528947 -0.08997387  0.04849774 -0.02729068\n",
            " -0.04997452 -0.09969886 -0.07096     0.15142027 -0.05783214  0.02461939\n",
            "  0.07498434 -0.3281993  -0.03076047 -0.0605084  -0.10856297 -0.11704553\n",
            "  0.08071601  0.18282418 -0.03948112 -0.05230116  0.01300049  0.06857167\n",
            " -0.04284734 -0.00544938 -0.01792841 -0.03874771  0.16116466  0.0228978\n",
            " -0.0933201   0.11920033 -0.1235325  -0.08237889 -0.05301567 -0.04881486\n",
            " -0.00839996  0.20597507  0.2569527  -0.20029084  0.0246927  -0.08771814\n",
            "  0.02670885  0.01759442  0.03386124 -0.05711829 -0.01111371  0.05325417\n",
            " -0.05557118  0.07558873 -0.05472465  0.06344538  0.1104325  -0.03305452\n",
            " -0.2622495  -0.01022405  0.11773416  0.03686656 -0.07780921 -0.02118384\n",
            "  0.04948857 -0.05293871 -0.12142148  0.01050999 -0.22693136 -0.13420835\n",
            "  0.10339355 -0.09209276 -0.01814071  0.10047316 -0.0480622   0.15476657\n",
            "  0.15168962  0.11423393 -0.17567511 -0.02471393 -0.08134394  0.03319516\n",
            "  0.16606073 -0.09424782 -0.16584048  0.01738706 -0.13618802  0.13118711\n",
            "  0.03602401 -0.02041692 -0.01296599 -0.10379691  0.08582206  0.06062648\n",
            " -0.012443   -0.15201403  0.01860246 -0.06474437 -0.09906236  0.02983027\n",
            "  0.01658299  0.00189586  0.0359318   0.1264988   0.09063986  0.09742837\n",
            "  0.09923454  0.07742707  0.3071979  -0.06277598 -0.01951267  0.06888813\n",
            " -0.14948173  0.14011416  0.05781556 -0.1007362   0.05099355  0.0247889\n",
            "  0.07655799  0.10206704 -0.02547554 -0.1418112  -0.04757425  0.06718909\n",
            "  0.00920768 -0.08352595  0.10561935 -0.0091678   0.10434889 -0.034185\n",
            " -0.10310828 -0.00515548 -0.02417523  0.00465526 -0.01557325 -0.06295312\n",
            " -0.0781668  -0.01073157  0.03376571  0.03899748  0.10504681 -0.07086447\n",
            " -0.15414959 -0.13985012 -0.10798711  0.05034737 -0.11540023  0.13892132\n",
            "  0.01912391  0.01066258  0.02330382  0.05406388 -0.01931763 -0.03498907\n",
            " -0.05669105 -0.00305242  0.07162343  0.00085184 -0.08007348  0.09395433\n",
            " -0.02948529 -0.14885148 -0.09232496 -0.02889086 -0.13753079  0.12938127]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPNWtVyvtnAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}