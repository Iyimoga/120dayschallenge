{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6fe062d0dc24e028cdbced241da37d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40e7bf60ddcd4bbca6e70840a50623ba",
              "IPY_MODEL_b94739714401481ab57f72ec8ad16ece",
              "IPY_MODEL_f976277fe52a4930901e226dc1551c3c"
            ],
            "layout": "IPY_MODEL_a77813acf1ff4e8681b460bffbe70539"
          }
        },
        "40e7bf60ddcd4bbca6e70840a50623ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c9698ab08c420984b10c28123e08a6",
            "placeholder": "​",
            "style": "IPY_MODEL_a63e66c7a7734754bbda9414fc6e8900",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b94739714401481ab57f72ec8ad16ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63ad8a7d3ff4232960a67250d23148c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d974afdfe37644c9b73e2eff13efdcce",
            "value": 3
          }
        },
        "f976277fe52a4930901e226dc1551c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef791fb638c44f78cfa918bac64f614",
            "placeholder": "​",
            "style": "IPY_MODEL_85ebfeb611ca4b268ff49a51293903fe",
            "value": " 3/3 [02:44&lt;00:00, 54.20s/it]"
          }
        },
        "a77813acf1ff4e8681b460bffbe70539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c9698ab08c420984b10c28123e08a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63e66c7a7734754bbda9414fc6e8900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e63ad8a7d3ff4232960a67250d23148c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d974afdfe37644c9b73e2eff13efdcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cef791fb638c44f78cfa918bac64f614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ebfeb611ca4b268ff49a51293903fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Running an LLM Locally"
      ],
      "metadata": {
        "id": "HJ8Tv_uMLJlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this recipe, we will learn how to load an LLM locally using the CPU or GPU and generate text from it after giving it a starting text as seed input. An LLM running locally can be instructed to generate text based on prompting. This new paradigm of generation of text via instruction prompting has brought the LLM to recent prominence. Learning to do this allows for control over hardware resources and environment setup, optimizing performance and enabling rapid experimentation or prototyping with text generation from seed inputs. This enhances data privacy and security, along with a reduced reliance on cloud services, and facilitates cost-effective deployment for educational and practical applications. As we run an LLM locally as part of the recipe, we will use instruction prompting to make it generate text based on a simple instruction."
      ],
      "metadata": {
        "id": "u2y0vmvOQtSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "XgFVKt8eQ0cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rh2LVNBNK-lR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-trained Model(mistrlai)"
      ],
      "metadata": {
        "id": "W08ojTdbRGdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"mistralai/Mistral-7B-Instruct-v0.2\""
      ],
      "metadata": {
        "id": "0UN_Lc1mRAdm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the tokenizer"
      ],
      "metadata": {
        "id": "7WN-VzxIRejB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "# Converts text to tokens (numbers)\n",
        "# Converts tokens to text (decoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQLsTkJZRXdV",
        "outputId": "05c7ed37-038b-43b0-e430-cc20810fb601"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Model"
      ],
      "metadata": {
        "id": "7KdW9QfpR4og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U bitsandbytes accelerate\n"
      ],
      "metadata": {
        "id": "m_cDE7Rsy82Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "model1 = AutoModelForCausalLM.from_pretrained(\n",
        "    model,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f6fe062d0dc24e028cdbced241da37d6",
            "40e7bf60ddcd4bbca6e70840a50623ba",
            "b94739714401481ab57f72ec8ad16ece",
            "f976277fe52a4930901e226dc1551c3c",
            "a77813acf1ff4e8681b460bffbe70539",
            "88c9698ab08c420984b10c28123e08a6",
            "a63e66c7a7734754bbda9414fc6e8900",
            "e63ad8a7d3ff4232960a67250d23148c",
            "d974afdfe37644c9b73e2eff13efdcce",
            "cef791fb638c44f78cfa918bac64f614",
            "85ebfeb611ca4b268ff49a51293903fe"
          ]
        },
        "id": "7i8i9im0Rl14",
        "outputId": "062eba83-fff1-4fa9-e409-e030772e52a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6fe062d0dc24e028cdbced241da37d6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Generation(Inference)\n",
        "prompt"
      ],
      "metadata": {
        "id": "00CGC-FaWi4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Explain what Natural Language Processing is in simple terms.\""
      ],
      "metadata": {
        "id": "5CtGNZ-4Xp4O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the Input"
      ],
      "metadata": {
        "id": "MJP-SzgMXuFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(prompt, return_tensors = \"pt\").to(model1.device) # Moved to same device as the model"
      ],
      "metadata": {
        "id": "K8Nwm9p4Xr3m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Text"
      ],
      "metadata": {
        "id": "sw2fAL37YPGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = model1.generate(\n",
        "      **inputs,\n",
        "      max_new_tokens = 150, # length of response\n",
        "      do_sample = True,  # enables non-greedy generation\n",
        "      temperature = 0.7  # creativity\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi13PBuSYC4t",
        "outputId": "8bb18f9c-38ac-4c14-f986-b69e247c71ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decode the output"
      ],
      "metadata": {
        "id": "ID1-UH5EY7ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response  = tokenizer.decode(output[0],\n",
        "                             skip_special_tokens = True)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "O4T2IIrMYl2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f9ad07-8cd3-4d97-e693-cbfe0db11283"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain what Natural Language Processing is in simple terms.\n",
            "\n",
            "Natural Language Processing, often referred to as NLP, is a subfield of artificial intelligence (AI) that focuses on enabling computers to understand, interpret, and generate human language. It's like teaching a computer to read, write, and speak human language, just as we humans do.\n",
            "\n",
            "NLP involves various techniques and algorithms to analyze, understand, and make sense of the meaning behind words, phrases, and sentences. It's used in various applications such as text summarization, sentiment analysis, speech recognition, machine translation, and more. Ultimately, NLP helps computers to communicate more effectively and naturally with humans, making our interactions more efficient and intuitive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9pOYxT7LrYB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}