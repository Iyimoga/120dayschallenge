{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a821187-bc10-4dde-a420-23da2d8f4dcb",
   "metadata": {},
   "source": [
    "# IMPLEMENTING RestNet FROM SCRATCH"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86628c9a-d583-49ca-816a-9b07a2ab0d65",
   "metadata": {},
   "source": [
    "Residual Network, or ResNet for short, constitutes one of the most groundbreaking\n",
    "advancements in deep learning. its architecture relies on a component called the\n",
    "residual module, which allows us to ensemble networks with depths that were unthinkable\n",
    "a couple of years ago. Tere are variants of ResNet that have more than 100 layers, without\n",
    "any loss of performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef51b5-2c33-4c0c-8990-84aa5e9a4e94",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797e0063-18d4-4050-95be-bb3ee395930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe5363-d4a9-4873-b73a-89d2c64fb71c",
   "metadata": {},
   "source": [
    "# Define an alias to tf.data.experimental.AUTOTUNE option, which we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1384d7cc-eac1-4dd4-8cd0-4481270733e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd47511-3b14-40a3-99eb-e9fd55cbf938",
   "metadata": {},
   "source": [
    "# Define a function to create a residual module in the ResNet architecture. Let start by specifying the function signature and implementing the first block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c284a5a0-4207-4cc7-8263-84e09c2f278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_eps = 2e-5  # maintain numerical stability in the optimizer's update calculations.\n",
    "bn_momentum = 0.9\n",
    "\n",
    "def residual_module(data,\n",
    "                   filters,\n",
    "                    stride,\n",
    "                   reduce = False,\n",
    "                    reg = 0.0001):\n",
    "    bn_1 = BatchNormalization(axis = -1,\n",
    "                             epsilon = bn_eps,\n",
    "                             momentum = bn_momentum) (data)\n",
    "    act_1 = ReLU() (bn_1)\n",
    "    conv_1 = Conv2D(filters = int(filters / 4),\n",
    "                   kernel_size = (1, 1),\n",
    "                   use_bias = False,\n",
    "                   kernel_regularizer = l2(reg)) (act_1)\n",
    "\n",
    "    # Implement the second Block\n",
    "\n",
    "    bn_2 = BatchNormalization(axis = -1,\n",
    "                           epsilon = bn_eps,\n",
    "                           momentum = bn_momentum) (conv_1)\n",
    "    act_2 = ReLU() (bn_2)\n",
    "    conv_2 = Conv2D(filters = int(filters / 4),\n",
    "                   kernel_size = (3, 3),\n",
    "                   strides = stride,\n",
    "                   padding = \"same\",\n",
    "                   use_bias = False,\n",
    "                   kernel_regularizer = l2(reg)) (act_2)\n",
    "    bn_3 = BatchNormalization(axis = -1,\n",
    "                             epsilon = bn_eps,\n",
    "                             momentum = bn_momentum) (conv_2)\n",
    "    act_3 = ReLU() (bn_3)\n",
    "    conv_3 = Conv2D(filters = filters,\n",
    "                   kernel_size = (1, 1),\n",
    "                   use_bias = False,\n",
    "                   kernel_regularizer = l2(reg)) (act_3)\n",
    "    if reduce:\n",
    "        shortcut = Conv2D(filters = filters,\n",
    "                         kernel_size = (1, 1),\n",
    "                         strides = stride,\n",
    "                         use_bias = False,\n",
    "                         kernel_regularizer = l2(reg)) (act_1)\n",
    "    x = Add() ([conv_3, shortcut])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281d447-8c4d-4d81-a49d-80b75542f985",
   "metadata": {},
   "source": [
    "# Define a function to build a custom ResNet network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b3c3b5-b648-49cc-94f6-2216f0b8193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape,\n",
    "                classes,\n",
    "                stages,\n",
    "                filters,\n",
    "                reg = 1e-3,\n",
    "                bn_eps = 2e-5,\n",
    "                bn_momentum = 0.9):\n",
    "    inputs = Input(shape = input_shape)\n",
    "    x = BatchNormalization(axis = -1,\n",
    "                          epsilon = bn_eps,\n",
    "                          momentum = bn_momentum) (inputs)\n",
    "\n",
    "    x = Conv2D(filters[0], (3, 3),\n",
    "              use_bias = False,\n",
    "              padding = \"same\",\n",
    "              kernel_regularizer = l2(reg)) (x)\n",
    "\n",
    "    for i in range(len(stages)):\n",
    "        stride = (1, 1) if i == 0 else (2, 2)\n",
    "        x = residual_module(data = x,\n",
    "                           filters = filters[i + 1],\n",
    "                           stride = stride,\n",
    "                           reduce = True,\n",
    "                           bn_eps = bn_eps,\n",
    "                           bn_momentum = bn_momentum)\n",
    "        for j in range(stages[i] - 1):\n",
    "            x = residual_module(data = x,\n",
    "                               filters = filters[i + 1],\n",
    "                               stride = (1, 1),\n",
    "                               bn_eps = bn_eps,\n",
    "                               bn_momentum = bn -momentum)\n",
    "            x = BatchNormalization(axis = -1,\n",
    "                                  epsilon = bn_eps,\n",
    "                                  momentum = bn_momentum) (x)\n",
    "            x = ReLU() (x)\n",
    "            x = AveragePooling2D((8, 8)) (x)\n",
    "\n",
    "            x = Flatten() (x)\n",
    "            x = Dense(classes, kernel_regularizer = l2(reg)) (x)\n",
    "            x = Softmax() (x)\n",
    "\n",
    "            return Model(inputs, x, name = \"resnet\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c565d7-7da5-4965-a28f-7a239751c6f2",
   "metadata": {},
   "source": [
    "# Define a function to load an image and its one-hot encode labels, based on its file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a338bb6c-0494-4290-934e-cee731643cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_and_label(image_path, target_size = (32, 32)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    image = tf.image.convert_image_dtype(image, np.float32)\n",
    "    image -= CINIC_MEAN_RGB # mean normalize\n",
    "    image = tf.image.resize(image, target_size)\n",
    "\n",
    "    label = tf.strings.split(image_path, os.path.sep) [-2]\n",
    "    label = (label == CINIC_10_CLASSES)  # one-hot encoded\n",
    "    label = tf.dtypes.cast(label, tf.float32)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8c018-ea0b-4e36-8ff3-f7642590d38f",
   "metadata": {},
   "source": [
    "# Define a function to create a tf.data.Dataset instance of images and labels from a glob-like pattern that refers to the folder where the images are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2151d00-31d0-4e57-9900-ee79828378c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_pattern, shuffle = False):\n",
    "    dataset = (tf.data.Dataset\n",
    "              .list_files(data_pattern)\n",
    "              .map(load_image_and_label,\n",
    "                  num_parallel_calls = AUTOTUNE)\n",
    "              .batch(BATCH_SIZE))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    return dataset.prefetch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988dddec-fa26-4e5c-81b1-ecb92ec9775d",
   "metadata": {},
   "source": [
    "# Define the mean RGB values of the CINIC-10 dataset, which is used in the load_image_and_label() function to mean normalize the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff34add0-db0d-4c49-9561-e2be17fe3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "CINIC_mean_RGB = np.array([0.47889522, 0.47227842, 0.43047404])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab9e55-3779-4364-956d-e8fca40611e9",
   "metadata": {},
   "source": [
    "# Define the classes of the CINIC-10 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e648e98-9ef8-4af2-a86d-9d32438c6e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "CINIC_10_CLASSES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"ship\", \"deer\", \"dog\", \n",
    "                   \"frog\", \"horse\", \"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b151a-8f1e-4a12-befb-85f76167da52",
   "metadata": {},
   "source": [
    "# Download the classes of the CINIC-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14f9ef5-5ffb-484c-a1d3-59c58ea30a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = ('https://datashare.is.ed.ac.uk/bitstream/handle/'\n",
    "                                '10283/3192/CINIC-10.tar.gz?'\n",
    "                                'sequence=4&isAllowed=y')\n",
    "DATA_NAME = 'cinic10'\n",
    "FILE_EXTENSION = 'tar.gz'\n",
    "FILE_NAME = '.'.join([DATA_NAME, FILE_EXTENSION])\n",
    "downloaded_file_location = get_file(origin=DATASET_URL,\n",
    "                                        fname=FILE_NAME,\n",
    "                                        extract=False)\n",
    "data_directory, _ = (downloaded_file_location\n",
    "                    .rsplit(os.path.sep, maxsplit=1))\n",
    "data_directory = os.path.sep.join([data_directory,\n",
    "                                   DATA_NAME])\n",
    "tar = tarfile.open(downloaded_file_location)\n",
    "if not os.path.exists(data_directory):\n",
    "    tar.extractall(data_directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca08b1e-2e25-4047-b3a2-4849186f3dae",
   "metadata": {},
   "source": [
    "# Define the glob-like patterns to train, test, and validation subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce89bcdb-52aa-46c2-aa17-ec32d74ca2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pattern = os.path.sep.join(\n",
    "    [data_directory, \"train/*/*.png\"]\n",
    ")\n",
    "\n",
    "test_pattern = os.path.sep.join(\n",
    "    [data_directory, \"test/*/*.png\"]\n",
    ")\n",
    "\n",
    "valid_pattern = os.path.sep.join(\n",
    "    [data_directory, \"valid/*/*.png\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9bd056-8110-4f5e-a2ef-4d1851fff83f",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9758ce87-53b5-4ef3-9d86-74acdd1cf1b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: C:\\\\Users\\\\HomePC\\\\.keras\\\\datasets\\\\cinic10\\\\train/*/*.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m BATCH_SIZE =\u001b[32m128\u001b[39m\n\u001b[32m      2\u001b[39m BUFFER_SIZE = \u001b[32m1024\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_dataset = \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                               \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m test_dataset = prepare_dataset(test_pattern)\n\u001b[32m      8\u001b[39m valid_dataset = prepare_dataset(valid_pattern)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mprepare_dataset\u001b[39m\u001b[34m(data_pattern, shuffle)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_dataset\u001b[39m(data_pattern, shuffle = \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      2\u001b[39m     dataset = (\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m              \u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_pattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m               .map(load_image_and_label,\n\u001b[32m      5\u001b[39m                   num_parallel_calls = AUTOTUNE)\n\u001b[32m      6\u001b[39m               .batch(BATCH_SIZE))\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m      8\u001b[39m         dataset = dataset.shuffle(BUFFER_SIZE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tensorflowProjects\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1329\u001b[39m, in \u001b[36mDatasetV2.list_files\u001b[39m\u001b[34m(file_pattern, shuffle, seed, name)\u001b[39m\n\u001b[32m   1322\u001b[39m condition = math_ops.greater(array_ops.shape(matching_files)[\u001b[32m0\u001b[39m], \u001b[32m0\u001b[39m,\n\u001b[32m   1323\u001b[39m                              name=\u001b[33m\"\u001b[39m\u001b[33mmatch_not_empty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1325\u001b[39m message = math_ops.add(\n\u001b[32m   1326\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mNo files matched pattern: \u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1327\u001b[39m     string_ops.reduce_join(file_pattern, separator=\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m), name=\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m assert_not_empty = \u001b[43mcontrol_flow_assert\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAssert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massert_not_empty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ops.control_dependencies([assert_not_empty]):\n\u001b[32m   1332\u001b[39m   matching_files = array_ops.identity(matching_files)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tensorflowProjects\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tensorflowProjects\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\control_flow_assert.py:102\u001b[39m, in \u001b[36mAssert\u001b[39m\u001b[34m(condition, data, summarize, name)\u001b[39m\n\u001b[32m    100\u001b[39m     xs = ops.convert_n_to_tensor(data)\n\u001b[32m    101\u001b[39m     data_str = [_summarize_eager(x, summarize) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m errors.InvalidArgumentError(\n\u001b[32m    103\u001b[39m         node_def=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    104\u001b[39m         op=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    105\u001b[39m         message=\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to be true. Summarized data: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m    106\u001b[39m         (condition, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(data_str)))\n\u001b[32m    107\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(name, \u001b[33m\"\u001b[39m\u001b[33mAssert\u001b[39m\u001b[33m\"\u001b[39m, [condition, data]) \u001b[38;5;28;01mas\u001b[39;00m name:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: C:\\\\Users\\\\HomePC\\\\.keras\\\\datasets\\\\cinic10\\\\train/*/*.png'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE =128\n",
    "BUFFER_SIZE = 1024\n",
    "train_dataset = prepare_dataset(train_pattern,\n",
    "                               shuffle = True)\n",
    "\n",
    "test_dataset = prepare_dataset(test_pattern)\n",
    "\n",
    "valid_dataset = prepare_dataset(valid_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd73a5-0bba-42bf-af59-69f80f7a66b7",
   "metadata": {},
   "source": [
    "# Build, Compile, and train a ResNet model. Because this is a time-consuming process, save a version of the model after each epoch, using the Model Chechpoint() callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6fb0d-3da3-4dc0-86f4-40534bc00386",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet(input_shape = (32, 32, 3),\n",
    "                    classes = 10,\n",
    "                    stages = (9, 9, 9),\n",
    "                    filters = (64, 64, 128, 256),\n",
    "                    reg = 5e-3)\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = \"rmsprop\",\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = \"./model.{epoch:02d} - {val_accuracy:.2f}.hdf5\",\n",
    "    save_weights_only = False,\n",
    "    monitor = \"val_accuracy\"\n",
    ")\n",
    "\n",
    "EPOCHS = 100\n",
    "model.fit(train_dataset,\n",
    "         validation_data = valid_dataset,\n",
    "          epochs = EPOCHS,\n",
    "          callbacks = [model_checkpoint_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca26cd-d7b5-4714-ae6a-b837034381df",
   "metadata": {},
   "source": [
    "# Load the best model(in this case, model.38-0.72.hdf5) and evaluate it on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afd5a88d-3149-467c-92db-83517a08a24c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mload_model\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mmodel.38-0.72.hdf5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m rsult =model.evaluate(test_dataset)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model.38-0.72.hdf5\")\n",
    "rsult =model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8edc9a-101b-434a-a24a-653b1899fc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
