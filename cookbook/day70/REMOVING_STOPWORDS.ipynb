{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# REMOVING STOPWORDS"
      ],
      "metadata": {
        "id": "YuxaJx-Bk3dD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we work with words, especially if we are considering words' semantics, we\n",
        "sometimes need to exclude some very frequent words that do not bring any substantial\n",
        "meaning to a sentence, words such as but, can, we, and so on. This recipe shows how to\n",
        "do that."
      ],
      "metadata": {
        "id": "Hj3G2_8OlIio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT THE csv AND nltk MODULES"
      ],
      "metadata": {
        "id": "TbmTaFdtllSI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sdf1uvGwk1Yw"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALIZE THE stopwords LIST"
      ],
      "metadata": {
        "id": "N7sL6NvZl1G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file = \"stopwords.csv\"\n",
        "with open(csv_file, \"r\", encoding = \"utf-8\") as fp:\n",
        "  reader = csv.reader(fp, delimiter = \",\", quotechar = \"'\")\n",
        "  stopwords = [row[0] for row in reader]"
      ],
      "metadata": {
        "id": "YKvtr4GClzy0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALTERNATIVELY, SET THE STOPWORDS LIST TO THE NLTK LISt"
      ],
      "metadata": {
        "id": "1wZUbhij6J1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "JDdNNylTn20l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd445dc4-a0ea-4fab-c882-740143237d72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "READ IN THE TEXT FILE"
      ],
      "metadata": {
        "id": "SOiiLLnU6uBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(r\"/content/stopwords.csv\", \"r\", encoding = \"utf-8\")\n",
        "text = file.read()"
      ],
      "metadata": {
        "id": "exGGharz6aev"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVE NEWLINES FOR BETTER READABILITIY"
      ],
      "metadata": {
        "id": "sDMbt8ce7O8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"\\n\", \" \")"
      ],
      "metadata": {
        "id": "UbVrRjZ_7MYz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZE THE TEXT"
      ],
      "metadata": {
        "id": "Ctx8ZGh97c_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = nltk.tokenize.word_tokenize(text)"
      ],
      "metadata": {
        "id": "LhpuGqXv7b1O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVE STOPWORDS"
      ],
      "metadata": {
        "id": "stUNvM_M7nfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = [word for word in words if word.lower() not in stopwords]"
      ],
      "metadata": {
        "id": "Iegq3UeL7l96"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CMncGMs7zH8",
        "outputId": "3fe616a6-360a-49aa-8bcc-8f595ebfd37a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['word', 'apple', 'beautiful', 'blue', 'book', 'bright', 'car', 'city', 'come', 'could', 'data', 'day', 'dog', 'eat', 'happy', 'home', 'light', 'love', 'man', 'play', 'see', 'sun', 'tree', 'walk']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TrVCT_Y273vx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}