{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2045ff-17b6-4d3f-90ab-fa63e52a236d",
   "metadata": {},
   "source": [
    "# FINE-TUNING A NETWORK USING THE KERAS API"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b045bec9-eabd-4434-bf6a-df3d38d28598",
   "metadata": {},
   "source": [
    "Perhaps one of the greatest advantages of transfer learning is its ability to seize the\n",
    "tailwind produced by the knowledge encoded in pre-trained networks. By simply\n",
    "swapping the shallower layers in one of these networks, we can obtain remarkable\n",
    "performance on new, unrelated datasets, even if our data is small. Why? Because the\n",
    "information in the bottom layers is virtually universal: It encodes basic forms and shapes\n",
    "that apply to almost any computer vision problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27121dfa-9ce7-4825-bdcc-4e03e724bb69",
   "metadata": {},
   "source": [
    "IMPORT NECESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "323ccad5-b591-4662-9c27-a37b738d280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f21a83-2eb0-4172-a7e4-f2fb37992393",
   "metadata": {},
   "source": [
    "SET RANDOM SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e6f8c4f-7d75-40e0-b0b5-229878180b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac0bef1-87f9-4dbb-9c07-5499783acac5",
   "metadata": {},
   "source": [
    "DEFINE A FUNCTION THAT WILL BUILD A NEW NETWORK FROMA PRE-TRAINED MODEL, WHERE THE TOP FULLY CONNECTED LAYERS WILL BE BRAND NEW AND ADAPTED TO THE PROBLEM AT HAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd8fe615-5f4f-4bc8-8a13-425e8a326a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(base_model, classes):\n",
    "    x = Flatten() (base_model.output)\n",
    "\n",
    "    x = Dense(units = 256) (x)\n",
    "    x = ReLU() (x)\n",
    "    x = BatchNormalization(axis = -1) (x)\n",
    "    x = Dropout(rate = 0.5) (x)\n",
    "\n",
    "    x = Dense(units = classes) (x)\n",
    "    output = Softmax() (x)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31425cb-b9ce-47ae-bb16-277d53526231",
   "metadata": {},
   "source": [
    "DEFINE A FUNCTION THAT WILL LOAD THE IMAGES AND LABELS IN THE DATASET AS NUMPY ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8bb14b3-646c-4868-bfed-0204dd5600e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(image_paths,\n",
    "                          target_size = (256, 256)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_path in image_paths:\n",
    "        image = load_img(image_path,\n",
    "                        target_size = target_size)\n",
    "        image = img_to_array(image)\n",
    "\n",
    "        label = image_path.split(os.Path.sep) [-2]\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa721ebc-9a36-4d3a-bf10-2f225aadb436",
   "metadata": {},
   "source": [
    "LOAD THE IMAGE AND EXTRACT THE SET OF CLASSES FROM THEM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e3e1e0f-bf81-46bc-a0a8-d54e43a8c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = (pathlib.Path.home() / r\"C:\\.keras\\datasets\\flowers17\\flowers17\\images\")\n",
    "files_pattern = (dataset_path / \"images\" / \"*\" / \"*.jpg\")\n",
    "image_paths = [*glob(str(files_pattern))]\n",
    "\n",
    "CLASSES = {p.split(os.path.sep) [-2] for p in image_paths}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb61042-395b-4fb7-a96a-618118eb14cf",
   "metadata": {},
   "source": [
    "LOAD THE IMAGES AND NORMALIZE THEM, ONE-HOT ENCODE THE LABELS WITH LABELBINARIZER(), AND SPLIT THE DATA INTO SUBSETS FOR TRAINING(80%) AND TESTING(20%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19001175-e646-42b3-b6f5-809e6142f41e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y has 0 samples: array([], dtype=float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m x, y = load_images_and_labels(image_paths)\n\u001b[32m      2\u001b[39m x = x.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[32m255.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m y = \u001b[43mLabelBinarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m (x_train, x_test,\n\u001b[32m      6\u001b[39m y_train, y_test) = train_test_split(x, y, test_size = \u001b[32m0.2\u001b[39m, random_state = SEED)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tensorflowProjects\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:335\u001b[39m, in \u001b[36mLabelBinarizer.fit_transform\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m    316\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[32m    317\u001b[39m \n\u001b[32m    318\u001b[39m \u001b[33;03m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    333\u001b[39m \u001b[33;03m        will be of CSR format.\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m.transform(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tensorflowProjects\\venv\\Lib\\site-packages\\sklearn\\base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\tensorflowProjects\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:309\u001b[39m, in \u001b[36mLabelBinarizer.fit\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMultioutput target data is not supported with label binarization\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     )\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33my has 0 samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % y)\n\u001b[32m    311\u001b[39m \u001b[38;5;28mself\u001b[39m.sparse_input_ = sp.issparse(y)\n\u001b[32m    312\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = unique_labels(y)\n",
      "\u001b[31mValueError\u001b[39m: y has 0 samples: array([], dtype=float64)"
     ]
    }
   ],
   "source": [
    "x, y = load_images_and_labels(image_paths)\n",
    "x = x.astype(\"float\") / 255.0\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "\n",
    "(x_train, x_test,\n",
    "y_train, y_test) = train_test_split(x, y, test_size = 0.2, random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706576e1-764d-44d1-ab5a-d91dc3c86b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
